# Context Builder Recipe (Memory Read Layer)
# Assembles relevant memories into focused context.md
# Architecture: architecture/DOCUMENT-IO-SYSTEM/PROMPT_MANAGEMENT_SYSTEM.md

name: context_builder
category: memory
role: context_builder
mode: null  # Unified for both chat and code
temperature: 0.3

prompt_fragments:
  - "apps/prompts/memory/context_builder.md"

input_docs:
  - path: "user_query"
    optional: false
    max_tokens: 300
    path_type: "inline"
    description: "What is the user asking? (guides memory selection)"

  - path: "prior_turn_summary"
    optional: true
    max_tokens: 300
    path_type: "inline"
    description: "Previous turn context for conversation continuity"

  - path: "memory_sources"
    optional: true
    max_tokens: 1500
    path_type: "inline"
    description: "Available memory documents (preferences, facts, learnings)"

output_doc:
  path: "context.md"
  section: "context"
  description: "Assembled context for downstream roles"

token_budget:
  total: 4000
  prompt: 700           # Fixed cost: context_builder.md prompt
  input_docs: 1800      # Budget for query + prior_turn + memory sources
  output: 1300          # Expected context output
  buffer: 200           # Safety margin (~5%)

llm_params:
  temperature: 0.3
  max_tokens: 1500

output_schema: CONTEXT  # Markdown document

description: |
  Context Builder (Memory Read Layer) assembles relevant context.

  This role runs FIRST in every turn, before Reflection.
  It reads from persistent memory storage and creates context
  that all downstream roles consume.

  **Input Sources:**
  - user_query: What the user is asking (guides memory selection)
  - prior_turn_summary: Previous turn (if follow-up query)
  - Memory storage (panda_system_docs/memory/):
    - user_preferences.md: Budget, brand preferences, locations
    - user_facts.md: Personal info user has shared
    - system_learnings.md: System knowledge (retailer info, etc.)
    - domain_knowledge.md: Reusable facts from research
    - lessons/: Specific patterns that worked/failed

  **Memory Selection Strategy:**
  1. ALWAYS include: prior_turn_summary (if exists)
  2. Query-relevant: user preferences related to query domain
  3. User facts: if query references "my" or personal context
  4. System learnings: if relevant to query type
  5. EXCLUDE: unrelated domains, stale information

  **Why LLM-Driven (not mechanical retrieval):**
  - Understands "user asking about drones" -> retrieve "user prefers DJI"
  - Can compress multiple memories into coherent summary
  - Decides what's NOT relevant (cooking prefs not needed for drone query)

  **Output:** context consumed by Reflection, Planner, Coordinator
